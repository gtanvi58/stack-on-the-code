# -*- coding: utf-8 -*-
"""stackonthecodellmwithoutrankingtest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_gw2gS5oqsEqnGeCL9vYOnuvTT5fxEqI
"""

import pandas as pd
import itertools
import json


def generate_summary(model, tokenizer, code, max_length=1024):
    # Generate summary for the entire code
    input_ids = tokenizer(code, return_tensors="pt", max_length=max_length, truncation=True).input_ids
    summary_ids = model.generate(input_ids, max_length=max_length)
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary


def summary_gen(data):

    #json_obj = sys.argv[2]
    #data = json.load(json_obj)


    # Initialize lists to store extracted data
    owner_reputation = []
    score = []
    body_text = []

    # Extract data from JSON
    for post in data:
        owner_reputation.append(post['owner']['reputation'])
        score.append(post['score'])
        body_text.append(post['body'])

    # Split body text into code and non-code parts
    code_snippets = []
    non_code_texts = []

    for text in body_text:
        code = ""
        non_code = ""
        in_code_block = False

        for line in text.split('\n'):
            if line.strip().startswith("<pre"):
                in_code_block = True
            elif line.strip().startswith("</pre>"):
                in_code_block = False
            elif in_code_block:
                code += line + "\n"
            else:
                non_code += line + "\n"

        code_snippets.append(code.strip())
        non_code_texts.append(non_code.strip())





    # Create DataFrame
    df = pd.DataFrame({
        'Owner Reputation': owner_reputation,
        'Score': score,
        'Post':body_text,
        'Code Snippet': code_snippets,
        'Text': non_code_texts
    })

    # Sort DataFrame by rank
    #df = df.sort_values(by='Rank', ascending=True)

    # Reset index
    #df.reset_index(drop=True, inplace=True)

    # Display DataFrame
    top3=df[:3]
    top3

    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

    tokenizer = AutoTokenizer.from_pretrained("sshleifer/distilbart-cnn-12-6")
    model = AutoModelForSeq2SeqLM.from_pretrained("sshleifer/distilbart-cnn-12-6")


    bodies = list(top3['Post'])
    codes = list(top3['Code Snippet'])

    summary=[]
    for body, code in zip(bodies, codes):
        full_summary = generate_summary(model, tokenizer, body)
        summary.append("Post Summary:" + "\n" +full_summary + "\n"  + "\n"+ code)

    json_object_result = json.dumps(summary, indent=4)
    with open('./results.json', "w") as outfile:
        outfile.write(json_object_result)
    print("OK")

with open('./answers.json', 'r') as file:
    data = json.load(file)

summary_gen(data)